{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13a3e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### PANDA SERIES ##########################3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2ab7f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[52.22 45.6  70.9  35.6  23.9 ]\n",
      "oil_prices\n",
      "float64\n",
      "[52.22 45.6  70.9  35.6  23.9 ]\n",
      "RangeIndex(start=0, stop=5, step=1)\n",
      "<bound method NDFrame._add_numeric_operations.<locals>.mean of 0    52.22\n",
      "1    45.60\n",
      "2    70.90\n",
      "3    35.60\n",
      "4    23.90\n",
      "Name: oil_prices, dtype: float64>\n",
      "(5,)\n",
      "0    52.22\n",
      "1     45.6\n",
      "2     70.9\n",
      "3     35.6\n",
      "4     23.9\n",
      "Name: oil_prices, dtype: string\n"
     ]
    }
   ],
   "source": [
    "#series- are pandas data structure built on top of numpy arrays\n",
    "#seriouse must be 1 dimentional\n",
    "# setouse key properties\n",
    "#values,index,name,dtype\n",
    "#astype used to convert to different data type\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "oil_data_array = np.array([52.22,45.6,70.9,35.6,23.9])\n",
    "print(oil_data_array)\n",
    "oil_data = pd.Series(oil_data_array, name=\"oil_prices\")\n",
    "print(oil_data.name)\n",
    "print(oil_data.dtype)\n",
    "print(oil_data.values)\n",
    "print(oil_data.index)\n",
    "print(oil_data.mean)\n",
    "print(oil_data.shape)\n",
    "print(oil_data.astype(\"string\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09051e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coffee       0\n",
      "banana       5\n",
      "tea        155\n",
      "coconut      0\n",
      "sugar      518\n",
      "Name: sales, dtype: int64\n",
      "banana       5\n",
      "tea        155\n",
      "coconut      0\n",
      "Name: sales, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#custom indices\n",
    "sales=[0,5,155,0,518]\n",
    "items=[\"coffee\",\"banana\",\"tea\",\"coconut\",\"sugar\"]\n",
    "sales_series = pd.Series(sales, index=items,name = \"sales\"\n",
    "                        )\n",
    "print(sales_series)\n",
    "print(sales_series[\"banana\":\"coconut\"]) #slicing with custom values make it inclusive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "492c4134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "day1    1\n",
      "day2    2\n",
      "day3    3\n",
      "day4    4\n",
      "dtype: int64\n",
      "1\n",
      "day1    1\n",
      "day2    2\n",
      "day3    3\n",
      "dtype: int64\n",
      "0      0\n",
      "2      1\n",
      "3      2\n",
      "4      3\n",
      "100    4\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    2\n",
       "3    3\n",
       "4    4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#iloc=>used to access values by their positional index.its same as indexing and slicing\n",
    "#df.iloc[row position,column position]\n",
    "#loc-used to access values by their custom labels\n",
    "#df.loc[row label,column label]\n",
    "my_series = pd.Series([0,1,2,3,4],index=[\"day0\",\"day1\",\"day2\",\"day3\",\"day4\"])\n",
    "print(my_series.iloc[1])\n",
    "print(my_series.iloc[1:5])\n",
    "print(my_series.loc[\"day1\"])\n",
    "print(my_series.loc[\"day1\":\"day3\"])\n",
    "my_series.index = [0,2,3,4,100]\n",
    "print(my_series)\n",
    "my_series.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "573cac9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-12    52.22\n",
      "2017-15    45.60\n",
      "2017-10    70.90\n",
      "2016-11    35.60\n",
      "2017-30    23.90\n",
      "dtype: float64\n",
      "2016-12    52.22\n",
      "2017-15    45.60\n",
      "2017-10    70.90\n",
      "2016-11    35.60\n",
      "2017-30    23.90\n",
      "dtype: float64\n",
      "48.91\n",
      "29.75\n",
      "2017-15    45.6\n",
      "2017-10    70.9\n",
      "2016-11    35.6\n",
      "dtype: float64\n",
      "0    52.22\n",
      "1    45.60\n",
      "2    70.90\n",
      "3    35.60\n",
      "4    23.90\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#add index as date to oil_data\n",
    "#take mean of first 2 and last 2 price\n",
    "#take prices from date 2017-15 to 2016-11\n",
    "#revert index back to integer\n",
    "oil_data_array = pd.Series([52.22,45.6,70.9,35.6,23.9])\n",
    "print(oil_data)\n",
    "oil_data.index=[\"2016-12\",\"2017-15\",\"2017-10\",\"2016-11\",\"2017-30\"]\n",
    "print(oil_data)\n",
    "first_two=oil_data.iloc[0:2].mean()\n",
    "last_two = oil_data.iloc[-2:].mean()\n",
    "print(first_two)\n",
    "print(last_two)\n",
    "print(oil_data[\"2017-15\":\"2016-11\"])\n",
    "print(oil_data.reset_index(drop=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "31d89476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4    23.90\n",
      "3    35.60\n",
      "1    45.60\n",
      "0    52.22\n",
      "dtype: float64\n",
      "23.9\n",
      "1    45.6\n",
      "3    35.6\n",
      "4    23.9\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#####sorting and filtering\n",
    "#filtering is done by using loc method and using conditions\n",
    "#sorting => sort_values,sort_index(scending=False)\n",
    "\n",
    "#get lowest price and sorted by date in decending  order\n",
    "#filter price<=50\n",
    "oil_data_array = pd.Series([52.22,45.6,70.9,35.6,23.9])\n",
    "oil_data.index=[\"2016-12\",\"2017-15\",\"2017-10\",\"2016-11\",\"2017-30\"]\n",
    "print(oil_data_array.sort_values().iloc[:4].sort_index(ascending=False))\n",
    "print(oil_data.min())\n",
    "con =oil_data_array.values <= 50 #or oil_data_array.values.le(50)\n",
    "print(oil_data_array.iloc[con])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b488117",
   "metadata": {},
   "outputs": [],
   "source": [
    "#string methods- accesed using str accessor\n",
    "1. strip(),lstrip(),rstrip()\n",
    "2.upper(),lower()\n",
    "3.slice(start,stop,step)\n",
    "4.count(\"string\")\n",
    "5.contains(\"string\")\n",
    "6.replace(\"a\",\"b\")\n",
    "7.split(\"delimiter\", expand=True)\n",
    "8.len()\n",
    "9. startswith(\"string\"), endswith(\"string\")\n",
    "10.str[start:end:step] =>strinh indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "63a39d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([12, 15, 10, 11, 30], dtype='int32')\n"
     ]
    }
   ],
   "source": [
    "#series operation\n",
    "# increase oil price by 10 % and add 2 dollers in it\n",
    "#create a series which represent percentage difference between original pice and max price\n",
    "# extract the month from string date in the index and store them s integer\n",
    "\n",
    "oil_data = pd.Series([52.22,45.6,70.9,35.6,23.9])\n",
    "oil_data.index=[\"2016-12\",\"2017-15\",\"2017-10\",\"2016-11\",\"2017-30\"]\n",
    "#print(oil_data)\n",
    "latest_oil_data=oil_data*1.1+2\n",
    "#print(latest_oil_data)\n",
    "max_price = latest_oil_data.max()\n",
    "#print((latest_oil_data-max_price)/max_price)\n",
    "print(latest_oil_data.index.str[5:].astype(int)) #str[start:end] string indexing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f7e44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#series aggregation methods\n",
    "1.count()\n",
    "2.first(),last()\n",
    "3.mean(),median()\n",
    "4.min(),max()\n",
    "5.argmax(),argmin() =>return index of min and max\n",
    "6.std(),var()=>standard deviation and variance\n",
    "7.mad()=> mean absolute deviation\n",
    "8.prod() =>product of items\n",
    "9.sum()\n",
    "10.quantile()=>percentiles\n",
    "#categorial series aggregation\n",
    "1. unique()=>reatuen an array of unique items\n",
    "2.nunique()=>return the number of unique items\n",
    "3.value_counts()=> return series of uniques items and their frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "9dbbf3d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52    0.2\n",
      "45    0.2\n",
      "70    0.2\n",
      "35    0.2\n",
      "23    0.2\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "##series aggregation\n",
    "#calculate sum,mean of month march\n",
    "#calculate how many prices have in month of december\n",
    "#calculate 10th and 90th percentiles of all data\n",
    "#how often did integer value occure in data\n",
    "import pandas as pd\n",
    "oil_data = pd.Series([52.22,45.6,70.9,35.6,23.9])\n",
    "oil_data.index=[\"2016-12\",\"2017-5\",\"2017-10\",\"2016-5\",\"2017-30\"]\n",
    "oil_data.index=oil_data.index.str[5:]\n",
    "#print(oil_data.loc[5]) or oil_data[5]\n",
    "#print(oil_data.loc[5].mean())\n",
    "#print(oil_data.loc[5].sum())\n",
    "new=oil_data.index.isin([\"10\"])\n",
    "#print(oil_data.loc[new].count())\n",
    "#print(oil_data.quantile([0.1,0.9]))\n",
    "print(oil_data.astype(int).value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4cc3ef7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "0    35.6\n",
      "1    35.6\n",
      "2    70.9\n",
      "3    35.6\n",
      "4    23.9\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "###Missing value(np.NaN,pd.NA)\n",
    "#isna()\n",
    "#dropna(),fillna(value)=>to handle na\n",
    "\n",
    "#some erroneous prices in data so filled in with missing values\n",
    "#calculate number of missing values\n",
    "#fill the prices in with median of oil price series\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "oil_data = pd.Series([51.44,47.8,70.9,35.6,23.9])\n",
    "oil_data= oil_data.where(~oil_data.isin([51.44,47.8]),np.NaN)\n",
    "print(oil_data.isna().sum()) #or print(oil_data.value_counts(dropna=False))\n",
    "print(oil_data.fillna(oil_data.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e259419c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['even' 'odd' 'even' 'odd' 'even' 'odd' 'even' 'odd' 'even' 'odd' 'even']\n",
      "0     even\n",
      "1      odd\n",
      "2     even\n",
      "3      odd\n",
      "4     even\n",
      "5      odd\n",
      "6     even\n",
      "7      odd\n",
      "8     even\n",
      "9      odd\n",
      "10    even\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "##apply custom function\n",
    "#apply=> lets u apply custom functions to pandas series.\n",
    "#where function=>numpy and pandas where function have little difference\n",
    "#numpy where syntax=> .where(condion,value if true,value if false)\n",
    "#pandas where syntax=>.where(condion,value if false,inplace=False)\n",
    "#EX-\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "array = pd.Series(range(11))\n",
    "#solve with numpy where\n",
    "np_where=np.where(array%2==0,\"even\",\"odd\")\n",
    "print(np_where)\n",
    "pd_where=array.where(array%2==0,\"odd\").where(~array%2==0,\"even\")\n",
    "print(pd_where)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7d92aefa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     buy\n",
       "1     buy\n",
       "2    wait\n",
       "3     buy\n",
       "4     buy\n",
       "dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###apply and where\n",
    "#\n",
    "import pandas as pd\n",
    "oil_data = pd.Series([51.44,47.8,70.9,35.6,0.8])\n",
    "def buy_bool(price,limit):\n",
    "    if price<limit:\n",
    "        return \"buy\"\n",
    "    return \"wait\"\n",
    "oil_data.apply(buy_bool,args=(oil_data.quantile(.9),))\n",
    "#or oil_data.apply(labda x: \"buy\" if x<oil_series.quantiles(0.9) else \"wait\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113def4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####key takeaways\n",
    "1. pandas series add an index and title to numpy array\n",
    "2. use loc and iloc method\n",
    "3.pandas and numpy have similar operation for filtering,sorting,aggregating\n",
    "4.pandas let u easily handle missing data\n",
    "5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47638f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Data Frames #######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3ffa630b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83488\n",
      "Index(['date', 'store_nbr', 'transactions'], dtype='object')\n",
      "date            object\n",
      "store_nbr        int64\n",
      "transactions     int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "## DataFrame Basics\n",
    "# shape,index,columns,axes,dtypes\n",
    "#1.read data from transcation.csv file\n",
    "#2.how many rows are in data,which columns are in data and their datatypes\n",
    "import pandas as pd\n",
    "transcation_data = pd.read_csv(\"demo/Pandas Course Resources/retail/transactions.csv\")\n",
    "#print(transcation_data)\n",
    "print(transcation_data.shape[0])\n",
    "print(transcation_data.columns)\n",
    "print(transcation_data.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "97b451f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date  store_nbr  transactions\n",
      "0  2013-01-01         25           770\n",
      "1  2013-01-02          1          2111\n",
      "2  2013-01-02          2          2358\n",
      "3  2013-01-02          3          3487\n",
      "4  2013-01-02          4          1922\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 83488 entries, 0 to 83487\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   date          83488 non-null  object\n",
      " 1   store_nbr     83488 non-null  int64 \n",
      " 2   transactions  83488 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 1.9+ MB\n",
      "None\n",
      "          store_nbr  transactions\n",
      "count  83488.000000  83488.000000\n",
      "mean      26.939237   1694.602158\n",
      "std       15.608204    963.286644\n",
      "min        1.000000      5.000000\n",
      "25%       13.000000   1046.000000\n",
      "50%       27.000000   1393.000000\n",
      "75%       40.000000   2079.000000\n",
      "max       54.000000   8359.000000\n",
      "1694.6021583940208\n",
      "1393.0\n",
      "5\n",
      "8359\n"
     ]
    }
   ],
   "source": [
    "# head(nrow),tail(nrow),saple(nrow),info(),describe(include)\n",
    "#1. print first 5 rows of transactions data\n",
    "#2.check is there any missing values\n",
    "#3.check unique dates\n",
    "#4.calculate mean,median,min,max of transaction\n",
    "transaction_data = pd.read_csv(\"demo/Pandas Course Resources/retail/transactions.csv\")\n",
    "print(transaction_data.head(5)) #1\n",
    "print(transaction_data.info()) #2 total rows and non-null count is same(83488) so no null values\n",
    "print(transaction_data.describe())\n",
    "print(transaction_data[\"transactions\"].mean()) #4\n",
    "print(transaction_data[\"transactions\"].median())\n",
    "print(transaction_data[\"transactions\"].min())\n",
    "print(transaction_data[\"transactions\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "249e5f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       store_nbr  transactions\n",
      "0             25           770\n",
      "1              1          2111\n",
      "2              2          2358\n",
      "3              3          3487\n",
      "4              4          1922\n",
      "...          ...           ...\n",
      "83483         50          2804\n",
      "83484         51          1573\n",
      "83485         52          2255\n",
      "83486         53           932\n",
      "83487         54           802\n",
      "\n",
      "[83488 rows x 2 columns]\n",
      "54\n",
      "141478945\n"
     ]
    }
   ],
   "source": [
    "## accessing data frames\n",
    "#1.exclude date column\n",
    "#2. calculate unique store_nbr\n",
    "#3total number of transactions\n",
    "transaction_data = pd.read_csv(\"demo/Pandas Course Resources/retail/transactions.csv\")\n",
    "#print(transaction_data.head())\n",
    "modified_df=transaction_data.loc[:,[\"store_nbr\",\"transactions\"]]\n",
    "print(modified_df) #1\n",
    "print(transaction_data[\"store_nbr\"].nunique()) #2\n",
    "print(transaction_data[\"transactions\"].sum()) #3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "01a47257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             date  store_nbr  transactions\n",
      "83434  2017-08-15          1          1693\n",
      "83435  2017-08-15          2          1737\n",
      "83436  2017-08-15          3          2956\n",
      "83437  2017-08-15          4          1283\n",
      "83438  2017-08-15          5          1310\n"
     ]
    }
   ],
   "source": [
    "### Droping data=> drop()\n",
    "#duplicates=>duplicated(), drop_duplicates()\n",
    "#1.drop 1st row permanantly\n",
    "#2.drop date colum but not in place\n",
    "#3 keep only last transactions of every date in dataframe\n",
    "transaction_data = pd.read_csv(\"demo/Pandas Course Resources/retail/transactions.csv\")\n",
    "transaction_data.drop(0,axis=0,inplace=True) #1\n",
    "#print(transaction_data)\n",
    "#print(transaction_data.drop(\"date\",axis=1)) #2\n",
    "print(transaction_data.drop_duplicates(subset=\"store_nbr\",keep=\"last\").head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "5e0a8848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "43\n",
      "0       65.323793\n",
      "1       93.140000\n",
      "2       92.970000\n",
      "3       93.120000\n",
      "4       93.200000\n",
      "          ...    \n",
      "1213    47.650000\n",
      "1214    46.400000\n",
      "1215    46.460000\n",
      "1216    45.960000\n",
      "1217    47.260000\n",
      "Name: dcoilwtico, Length: 1218, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "### Missing data\n",
    "# we can count missing values using .isna() and .sum()\n",
    "# or else .info() method\n",
    "#dropna(),fillna()\n",
    "\n",
    "#1.count missing values of dates or price\n",
    "#2. fill the Nan price value with 0 and fill nan value with mean value\n",
    "oil_data = pd.read_csv(\"demo/Pandas Course Resources/retail/oil.csv\")\n",
    "#print(oil_data)\n",
    "print(oil_data[\"date\"].isna().sum()) #1\n",
    "# or print(oil_data.info()) #1\n",
    "print(oil_data[\"dcoilwtico\"].isna().sum()) #1\n",
    "oil_data[\"dcoilwtico\"].fillna(0).mean() #2\n",
    "print(oil_data[\"dcoilwtico\"].fillna(oil_data[\"dcoilwtico\"].fillna(0).mean())) #2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "b1bd4cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26680481027213493\n",
      "144903\n"
     ]
    }
   ],
   "source": [
    "##Filtering\n",
    "#we can filter by passing condition in loc method\n",
    "#.query()=>we can use query like structure to filter data(by using and or)\n",
    "\n",
    "#1.calculate the % of times all store had more than 2000 transaction\n",
    "transaction_data = pd.read_csv(\"demo/Pandas Course Resources/retail/transactions.csv\")\n",
    "#print(transaction_data) \n",
    "print((transaction_data[\"transactions\"]> 2000).mean()) #1\n",
    "conn = (transaction_data[\"store_nbr\"] == 25) & (transaction_data[\"transactions\"]> 2000)\n",
    "print(transaction_data.loc[conn,\"transactions\"].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "452f4305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             date  store_nbr  transactions\n",
      "52011  2015-12-23         44          8359\n",
      "71010  2016-12-23         44          8307\n",
      "16570  2013-12-23         44          8256\n",
      "33700  2014-12-23         44          8120\n",
      "16572  2013-12-23         46          8001\n",
      "             date  store_nbr  transactions\n",
      "0      2013-01-01         25           770\n",
      "40     2013-01-02         46          4886\n",
      "38     2013-01-02         44          4821\n",
      "39     2013-01-02         45          4208\n",
      "41     2013-01-02         47          4161\n",
      "...           ...        ...           ...\n",
      "83455  2017-08-15         22           766\n",
      "83449  2017-08-15         16           742\n",
      "83465  2017-08-15         32           615\n",
      "83468  2017-08-15         35           612\n",
      "83459  2017-08-15         26           534\n",
      "\n",
      "[83488 rows x 3 columns]\n",
      "             date  store_nbr  transactions\n",
      "0      2013-01-01         25           770\n",
      "1      2013-01-02          1          2111\n",
      "2      2013-01-02          2          2358\n",
      "3      2013-01-02          3          3487\n",
      "4      2013-01-02          4          1922\n",
      "...           ...        ...           ...\n",
      "83483  2017-08-15         50          2804\n",
      "83484  2017-08-15         51          1573\n",
      "83485  2017-08-15         52          2255\n",
      "83486  2017-08-15         53           932\n",
      "83487  2017-08-15         54           802\n",
      "\n",
      "[83488 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "### sorting dataFrame=>sort_index(),sort_values()\n",
    "#1. get dataset includes the 5 days with the highest transactions count\n",
    "#2.get sorted dataset by date in ascending order but with highest transaction first\n",
    "#sort columns in reverse order\n",
    "import pandas as pd\n",
    "transaction_data = pd.read_csv(\"demo/Pandas Course Resources/retail/transactions.csv\")\n",
    "print(transaction_data.sort_values(\"transactions\",ascending = False).iloc[:5])  #1\n",
    "print(transaction_data.sort_values([\"date\",\"transactions\"],ascending =[True,False]))\n",
    "print(transaction_data.sort_index(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d10c5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             date  store_nbr  transactions\n",
      "0      2013-01-01         25           770\n",
      "1      2013-01-02          1          2111\n",
      "2      2013-01-02          2          2358\n",
      "3      2013-01-02          3          3487\n",
      "4      2013-01-02          4          1922\n",
      "...           ...        ...           ...\n",
      "83483  2017-08-15         50          2804\n",
      "83484  2017-08-15         51          1573\n",
      "83485  2017-08-15         52          2255\n",
      "83486  2017-08-15         53           932\n",
      "83487  2017-08-15         54           802\n",
      "\n",
      "[83488 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#Rename and reorder columns\n",
    "#1. rename transactions to transaction_count and store_nbr to store_number\n",
    "transaction_data = pd.read_csv(\"demo/Pandas Course Resources/retail/transactions.csv\")\n",
    "#print(transaction_data)\n",
    "transaction_data.rename(columns={\"store_nbr\":\"store_number\",\"transaction\":\"transaction_count\"})\n",
    "#or transaction_data.columns=[\"date\",\"store_number\",\"transaction_count\"]\n",
    "print(transaction_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "09c2e089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             date  store_nbr  transactions  pct_to_target\n",
      "0      2013-01-01         25           770         0.3080\n",
      "1      2013-01-02          1          2111         0.8444\n",
      "2      2013-01-02          2          2358         0.9432\n",
      "3      2013-01-02          3          3487         1.3948\n",
      "4      2013-01-02          4          1922         0.7688\n",
      "...           ...        ...           ...            ...\n",
      "83483  2017-08-15         50          2804         1.1216\n",
      "83484  2017-08-15         51          1573         0.6292\n",
      "83485  2017-08-15         52          2255         0.9020\n",
      "83486  2017-08-15         53           932         0.3728\n",
      "83487  2017-08-15         54           802         0.3208\n",
      "\n",
      "[83488 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "## Arithmetic and boolean column creation\n",
    "#1.create \"pct_to_target\" that devides transaction by 2500-our transaction target for all stores.\n",
    "#2.create \"met_target\" column that is true id \"pc_to_target\" >=1\n",
    "#3. craete \"bonus_payable\" is equal to 100 if \"met_target\" is True and o if not.then sum the total \"bonus_payable_amounr\"\n",
    "#4.create columns for month and day of week as integers.\n",
    "transaction_data = pd.read_csv(\"demo/Pandas Course Resources/retail/transactions.csv\")\n",
    "#print(transaction_data)\n",
    "transaction_data[\"pct_to_target\"] =transaction_data[\"transactions\"]/2500\n",
    "transaction_data[\"met_target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca901106",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
